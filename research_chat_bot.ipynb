{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f78245f-dcbd-499d-9d93-656d5a4545a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "class Model_Classifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_labels, dropout):\n",
    "        super(Model_Classifier, self).__init__()\n",
    "        # Instantiate BERT model\n",
    "        self.bert = RobertaModel.from_pretrained('roberta-large')\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout = dropout\n",
    "        self.linear = nn.Linear(self.embedding_dim, self.hidden_dim)\n",
    "        self.Drop = nn.Dropout(self.dropout)\n",
    "        self.linear2 = nn.Linear(self.hidden_dim, self.num_labels)\n",
    "        \n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.hidden_dim),\n",
    "            # nn.Dropout(self.dropout),\n",
    "            #nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.hidden_dim, self.num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "\n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0]\n",
    "\n",
    "        last_hidden_state_cls = self.linear(last_hidden_state_cls)\n",
    "\n",
    "        last_hidden_state_cls = self.Drop(last_hidden_state_cls)\n",
    "        \n",
    "\n",
    "        logits = self.linear2(last_hidden_state_cls)[:, 0, :]\n",
    "\n",
    "        #logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits, last_hidden_state_cls,outputs[0]\n",
    "class QModel_Classifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_labels, dropout,feature_remove_max= True):\n",
    "        super(QModel_Classifier, self).__init__()\n",
    "        # Instantiate BERT model\n",
    "        self.bert = RobertaModel.from_pretrained('roberta-large')\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout = dropout\n",
    "\n",
    "        \n",
    "        divisors = sorted(self.cf(embedding_dim,hidden_dim))\n",
    "        divisors1 = sorted(self.cf(hidden_dim,num_labels))\n",
    "        common_divisors = sorted(set(divisors1) & set(divisors))\n",
    "        if(feature_remove_max == True):\n",
    "            self.n = common_divisors[-1]\n",
    "        else :\n",
    "            self.n = common_divisors[0]\n",
    "        \n",
    "        self.linear = PHMLayer(self.embedding_dim, self.hidden_dim,self.n)\n",
    "        self.Drop = nn.Dropout(self.dropout)\n",
    "        self.linear2 = PHMLayer(self.hidden_dim, self.num_labels,self.n)\n",
    "        \n",
    "\n",
    "    def cf(self,num1,num2):\n",
    "            n=[]\n",
    "            g=gcd(num1, num2)\n",
    "            for i in range(1, int(sqrt(g))+1):\n",
    "                if g%i==0:\n",
    "                    n.append(i)\n",
    "                    if g!=i*i:\n",
    "                        n.append(int(g/i))\n",
    "            return n\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "\n",
    "        last_hidden_state_cls = outputs[0]\n",
    "        #print(last_hidden_state_cls.shape)\n",
    "        last_hidden_state_cls = self.linear(last_hidden_state_cls)\n",
    "        #print(last_hidden_state_cls.shape)\n",
    "        last_hidden_state_cls = self.Drop(last_hidden_state_cls)\n",
    "        #print(last_hidden_state_cls.shape)\n",
    "\n",
    "        logits = self.linear2(last_hidden_state_cls)[:, 0, :]\n",
    "        #print(logits.shape)\n",
    "        # Feed input to classifier to compute logits\n",
    "        #logits = self.classifier(last_hidden_state_cls)\n",
    "        \n",
    "        return logits, last_hidden_state_cls,outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5120c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import telebot\n",
    "import time\n",
    "from telebot import types\n",
    "import json\n",
    "import torch\n",
    "import argparse, os\n",
    "\n",
    "import datetime \n",
    "import pymongo\n",
    "\n",
    "class Record():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        \"\"\"\n",
    "        super(Record, self).__init__()\n",
    "        self.name = None\n",
    "        self.id = None\n",
    "        self.message = None\n",
    "        self.predicted = None\n",
    "        self.response = None\n",
    "        self.time = None\n",
    "\n",
    "def dir_path(string):\n",
    "    if os.path.isdir(string):\n",
    "        return string\n",
    "    else:\n",
    "        raise NotADirectoryError(string)\n",
    "        \n",
    "\n",
    "## ----- import pre-trained model\n",
    "\n",
    "import torch\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "eastern_tz = pytz.timezone('Europe/Moscow')\n",
    "\n",
    "\n",
    "class Args():\n",
    "    embedding_dim = 1024\n",
    "    hidden=512 \n",
    "    num_labels = 24\n",
    "    dropout=0.1\n",
    "    \n",
    "args = Args()\n",
    "PATH = r\"itmo_model.pt\"\n",
    "model = Model_Classifier(args.embedding_dim,args.hidden,args.num_labels,args.dropout)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', do_lower_case=True)\n",
    "\n",
    "record = Record()\n",
    "\n",
    "token = '6705181314:AAH1F4h1C_rpM5pkcu3tXdeHkznDxIESz3o'\n",
    "bot = telebot.TeleBot(token, parse_mode='None')\n",
    "bot_name = 'ITMO BOT'\n",
    "\n",
    "#model= torch.load('/Users/mac/Desktop/test/model.pth')\n",
    "\n",
    "token = 'mongodb+srv://mongo:mongo@cluster0.gcj8po2.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0'\n",
    "myclient = pymongo.MongoClient(token)\n",
    "\n",
    "def menu():\n",
    "        markup = types.InlineKeyboardMarkup()\n",
    "        markup.add(types.InlineKeyboardButton('help', callback_data='help'))   \n",
    "        markup.add(types.InlineKeyboardButton('contact', callback_data='contact'))   \n",
    "        markup.add(types.InlineKeyboardButton('main questions', callback_data='main questions'))  \n",
    "        markup.add(types.InlineKeyboardButton('more questions', callback_data='more questions')) \n",
    "        markup.add(types.InlineKeyboardButton('application', callback_data='application'))    \n",
    "        return markup\n",
    "def main():       \n",
    "    @bot.message_handler(commands=['start'])  # Ответ на команду /start\n",
    "    def start(message):\n",
    "        mess = f'hi, <b>{message.from_user.first_name}</b>!\\nI am - <b>{bot_name}</b>'\n",
    "\n",
    "        #record name and id \n",
    "        record.id = message.chat.id\n",
    "        record.name = message.from_user.first_name\n",
    "\n",
    "        \n",
    "        markup = menu()\n",
    "        msg = bot.send_message(message.chat.id, mess, reply_markup=markup, parse_mode='html')\n",
    "        #bot.register_next_step_handler(msg, force_button_click)\n",
    "\n",
    "def restart(message):\n",
    "    mess = f'hi, <b>{message.from_user.first_name}</b>!\\nI am - <b>{bot_name}</b>'\n",
    "    markup = menu()\n",
    "    msg = bot.send_message(message.chat.id, mess, reply_markup=markup, parse_mode='html')\n",
    "    #bot.register_next_step_handler(msg, force_button_click)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728a5ce3-6b32-4952-a60b-6a934f81cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stastical plot\n",
    "@bot.message_handler(commands=['plot'])\n",
    "def update_unknown_datasets(message):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9972dee-afc9-4e4a-802f-abf0d5e61b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate mondodb atlas\n",
    "from bson import ObjectId\n",
    "def mongodb_atlas(table_name):\n",
    "    \n",
    "    mydb = myclient[\"itmo_data\"]\n",
    "\n",
    "    mycol = mydb[table_name]\n",
    "\n",
    "    return mycol\n",
    "\n",
    "# to force users to click button\n",
    "def force_button_click(message):\n",
    "    if not message.text.startswith('/'):\n",
    "        bot.send_message(message.chat.id, 'You must click one of the buttons!')\n",
    "        \n",
    "    time.sleep(3)\n",
    "    restart(message)\n",
    "\n",
    "\n",
    "# to update unknown new datasets\n",
    "@bot.message_handler(commands=['itmoxxx'])\n",
    "def update_unknown_datasets(message):\n",
    "    mycol = mongodb_atlas('unknown_response') \n",
    "    unknows = []\n",
    "    for x in mycol.find():\n",
    "        unknows.append(x)   \n",
    "    \n",
    "    if(len(unknows)==0):\n",
    "        bot.send_message(message.chat.id, 'No more Unknown datasets, redirect to menu')\n",
    "        time.sleep(3)\n",
    "        restart(message)\n",
    "    else:\n",
    "               \n",
    "        max_length = 64 \n",
    "         \n",
    "        one_unknown = mycol.find_one()\n",
    "        msg = one_unknown['message']\n",
    "        \n",
    "        indexs,_ = model_process(model,tokenizer,msg,max_length,message)\n",
    "        markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "        for i in range(len(indexs)):\n",
    "            found = query(indexs[i])\n",
    "            markup.add(found[0]['responses'][0]) \n",
    "        markup.add('New Topic')\n",
    "        mess = 'Please choose more correspondent topic'\n",
    "        msg = bot.send_message(message.chat.id, mess, reply_markup=markup, parse_mode='html')\n",
    "        #send rest of unknown to next func\n",
    "        bot.register_next_step_handler(msg, insert_delete_unknow,one_unknown)\n",
    "\n",
    "def insert_delete_unknow(message,one_unknown):\n",
    "    msg = message.text\n",
    "    if(msg == 'New Topic'):\n",
    "        mess = 'please think a response for question'\n",
    "        msg = bot.send_message(message.chat.id,mess)\n",
    "        bot.register_next_step_handler(msg, insert_new_topic,one_unknown)\n",
    "    else:\n",
    "        mycol = mongodb_atlas('unknown_response')\n",
    "        mycol.delete_one({\"_id\":one_unknown['_id']}) \n",
    "        \n",
    "        one_unknown.pop('_id')\n",
    "        mycol = mongodb_atlas('new_response')\n",
    "        mycol.insert_one(one_unknown) \n",
    "        \n",
    "        bot.register_next_step_handler(message, update_unknown_datasets)   \n",
    "        \n",
    "\n",
    "def insert_new_topic(message,one_unknown):\n",
    "    msg = message.text\n",
    "\n",
    "    mycol = mongodb_atlas('unknown_response')\n",
    "    mycol.delete_one({\"_id\":one_unknown['_id']}) \n",
    "\n",
    "    one_unknown.pop('_id')\n",
    "    mycol = mongodb_atlas('new_response')\n",
    "    mycol.insert_one(one_unknown) \n",
    "        \n",
    "    mycol = mongodb_atlas('original')\n",
    "    mycol.insert_one(one_unknown) \n",
    "\n",
    "    mess = 'successfully updated'\n",
    "    bot.send_message(message.chat.id,mess)\n",
    "    bot.register_next_step_handler(message, update_unknown_datasets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da70424-14cc-4e9b-b74c-a98cef6ffb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirement\n",
      "\n",
      "scholarships\n",
      "\n",
      "batchmates\n",
      "\n",
      "language\n",
      "\n",
      "research topics\n",
      "\n",
      "internship\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in case for backup\n",
    "\n",
    "with open('/Users/mac/Desktop/SCIENTIFIC_RESEARCH/main_QA.json', 'r') as json_data:\n",
    "    main_intents = json.load(json_data)\n",
    "corpse = []\n",
    "responses = []\n",
    "for intent in main_intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    response = intent['responses']\n",
    "    print(tag+\"\\n\")\n",
    "    corpse.append(tag)# here we are appending the word with its tag\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17853e7f-6e0f-4736-b82f-547aaf59787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpse = ['requirement','scholarships','batchmates','research topics','internship']\n",
    "main_index = [0,1,2,3,4,5]\n",
    "mycol = mongodb_atlas('original')\n",
    "\n",
    "responses = []\n",
    "for i in range(len(main_index)):\n",
    "    x = mycol.find_one({'tag':main_index[i]})\n",
    "    responses.append(x['responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98593004-1eb5-425d-8336-d5b45f816d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_questions_function(call):\n",
    "    mess = 'please choose interested item'\n",
    "    markup = types.ReplyKeyboardMarkup(one_time_keyboard=True,resize_keyboard=True)\n",
    "    for i in range(len(corpse)):            \n",
    "        markup.add(corpse[i])  \n",
    "    markup.add('None')  \n",
    "    try :\n",
    "        id = call.message.chat.id\n",
    "    except :\n",
    "        id = call.chat.id\n",
    "    msg = bot.send_message(id,mess, reply_markup=markup)\n",
    "    types.ReplyKeyboardRemove()\n",
    "    bot.register_next_step_handler(msg, main_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1095a9d2-3f82-465f-af91-740ec26dbf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "@bot.callback_query_handler(func=lambda call: True)\n",
    "def message_reply(call):\n",
    "    if call.data == 'contact':\n",
    "        mess = 'click on mail to get contact with staff'\n",
    "        bot.send_message(call.message.chat.id,mess)\n",
    "        mess = \"\"\"\n",
    "Program coordinator --  aakarabintseva@itmo.ru\n",
    "International office -- international@itmo.ru\n",
    "Student office -- aakiseleva@itmo.ru\n",
    "Migration office -- aakhalilova@itmo.ru \n",
    "\"\"\"\n",
    "        bot.send_message(call.message.chat.id,mess)\n",
    "        time.sleep(5)\n",
    "        restart(call.message)\n",
    "    elif call.data == 'help': \n",
    "        mess = \"\"\"\n",
    "contact --  to find Email address of specific staff in ITMO\n",
    "main questions -- to answer most frequent questions from candidates\n",
    "more questions -- to answer other questions\n",
    "application -- to redirect to page to fill application\n",
    "\"\"\"\n",
    "        bot.send_message(call.message.chat.id,mess)\n",
    "        time.sleep(5)\n",
    "        restart(call.message)\n",
    "    elif call.data == 'main questions':\n",
    "        main_questions_function(call)\n",
    "    elif call.data == 'more questions':\n",
    "        msg = bot.send_message(call.message.chat.id, 'please write your questions')\n",
    "        bot.register_next_step_handler(msg, more_questions)\n",
    "    elif call.data == 'application':\n",
    "        linked_user = 'https://signup.itmo.ru/master'\n",
    "        markup = types.InlineKeyboardMarkup()\n",
    "        markup.add(types.InlineKeyboardButton(text='redirect to ITMO',\n",
    "                            url=linked_user))\n",
    "        mess = 'click to redirect to application form'\n",
    "        bot.send_message(call.message.chat.id,mess, reply_markup=markup)\n",
    "        time.sleep(5)\n",
    "        restart(call.message)\n",
    "    \n",
    "\n",
    "\n",
    "def main_questions(message):\n",
    "    def tokenize(sentence):\n",
    "        return regexp_tokenize(sentence, pattern=\"\\w+\")\n",
    "\n",
    "    def score_words(x,y):\n",
    "          \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "          intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "          union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "          return intersection_cardinality/float(union_cardinality)\n",
    "    sentence = message.text\n",
    "    if(any(sentence.lower()==item.lower() for item in [\"quit\",\"finish\",\"over\",\"bye\",\"goodbye\"])):\n",
    "        print(f\"{bot_name}: Goodbye , have a nice day\")\n",
    "\n",
    "    similarity = []\n",
    "    for i in corpse:\n",
    "        similarity.append(score_words(sentence,i))\n",
    "    #print(similarity)\n",
    "    \n",
    "    if(max(similarity) > 0.5 and len(tokenize(sentence))==1 ):\n",
    "        print(f\"{bot_name}: \"+responses[similarity.index(max(similarity))][0])\n",
    "    \n",
    "    mess = responses[similarity.index(max(similarity))][0]\n",
    "    bot.send_message(message.chat.id, mess,reply_markup=types.ReplyKeyboardRemove())\n",
    "\n",
    "    time.sleep(5)\n",
    "    restart(message)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b51d2c88-26d6-4848-b319-26a5b2367df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_questions(message):\n",
    "    mess = None\n",
    "    if(message.text == 'None'):\n",
    "        mess = 'redirecting to menu ...'\n",
    "        bot.send_message(message.chat.id, mess,reply_markup=types.ReplyKeyboardRemove())\n",
    "\n",
    "        time.sleep(3)\n",
    "        restart(message)\n",
    "    else:  \n",
    "        if(message.text in corpse):\n",
    "            msg = responses[corpse.index(message.text)][0]\n",
    "            print(f\"{bot_name}: \"+msg)\n",
    "            mess = msg\n",
    "        else:\n",
    "            msg = 'You must click one of the options!'\n",
    "            print(f\"{bot_name}: \"+msg)\n",
    "            mess = msg\n",
    "    \n",
    "        \n",
    "        bot.send_message(message.chat.id, mess,reply_markup=types.ReplyKeyboardRemove())\n",
    "    \n",
    "        time.sleep(5)\n",
    "        main_questions_function(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7033812b-7e13-4be5-990e-65779f9f3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_dialogue(record,name):\n",
    "\n",
    "    mydb = myclient[\"itmo_data\"]\n",
    "    mycol = mydb[name]\n",
    "    #mycol = mydb[\"customers\"]\n",
    "    now = datetime.now()\n",
    "    now_russia = eastern_tz.localize(now)            \n",
    "\n",
    "    mydict = { \"name\": record.name , \"id\": record.id, \"message\": record.message, \"predicted\":record.predicted, \"response\":record.response ,\"time\": now_russia }   \n",
    "    \n",
    "    x = mycol.insert_one(mydict)\n",
    "\n",
    "def query(keylabel):\n",
    "\n",
    "    \n",
    "    mydb = myclient[\"itmo_data\"]\n",
    "    \n",
    "    mycol = mydb[\"original\"]\n",
    "    \n",
    "    myquery = { \"tag\": keylabel }\n",
    "    \n",
    "    mydoc = mycol.find(myquery)\n",
    "    found = []\n",
    "    \n",
    "    for x in mydoc:\n",
    "      found.append(x)\n",
    "        \n",
    "    return found\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7944c81-9061-4576-b42e-53a0377b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_process(model,tokenizer,sent,max_length):\n",
    "    encoding = tokenizer(sent, return_tensors='pt', max_length=max_length, truncation=True)\n",
    "    b_input_ids = encoding['input_ids']\n",
    "    #token_type_ids = encoding['token_type_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "    outputs = model(b_input_ids, \n",
    "                    attention_mask=attention_mask)\n",
    "    m = nn.Softmax(dim=1)\n",
    "    outputs= m(outputs[0])\n",
    "    output_list = outputs[0].detach().numpy()\n",
    "    indexs = sorted(range(len(output_list)), key=lambda k: output_list[k], reverse=True)     \n",
    "    probs = output_list[indexs]\n",
    "\n",
    "    return indexs,probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead392ff-e210-4af5-abad-e4469e5a3d49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITMO BOT: We don't have our own scholarship funding within the program, but you can apply through the Russian government international scholarship website and choose our program in your application http://studyinrussia.ru/en/actual/scholarships/.\n",
      "item num :\n",
      "1\n",
      "\n",
      "['when will be the exam']\n",
      "when will be the exam\n",
      "\n",
      "[11, 8, 5, 16, 22, 6, 13, 2, 17, 10, 14, 9, 1, 7, 0, 4, 15, 20, 21, 19, 3, 18, 23, 12]\n",
      "11\n",
      "0.059175346\n",
      "\n",
      "record_correct_response\n",
      "11\n",
      "11\n",
      "11\n",
      "sents\n",
      "[]\n",
      "recommendations\n",
      "[8, 5, 16, 22, 6, 13, 2, 17, 10, 14, 9, 1, 7, 0, 4, 15, 20, 21, 19, 3, 18, 23, 12]\n",
      "[8, 5]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import re\n",
    "from torch import nn\n",
    "\n",
    "max_length = 64     \n",
    "\n",
    "\n",
    "def maximum(list):\n",
    "    output = list.sort()\n",
    "    return output[0][-3:] , output[1][-3:]\n",
    "    #return [output[1][-1],output[1][-2],output[1][-3]]\n",
    "def multiple_question_detect(sent):\n",
    "    if(type(sent) == list):\n",
    "        return sent\n",
    "    sent = sent.replace('?',' ?')\n",
    "    sent = re.sub(r'\\s\\s+',' ',sent)\n",
    "    sent = re.sub(r\"^\\s+|\\s+$\", \"\", sent)\n",
    "    sent = re.split('(?<=[.!?,]) +',sent)\n",
    "    texts = []\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = re.sub('[^a-zA-Z0-9 ]', '', sent[i])\n",
    "        sent[i] = re.sub(r\"^\\s+|\\s+$\", \"\", sent[i])\n",
    "        if(len(sent[i])==0):\n",
    "            texts.append(sent[i])\n",
    "    \n",
    "    for i in texts :\n",
    "        sent.remove(i)\n",
    "    return sent\n",
    "\n",
    "def recommendations(message,advice_options):\n",
    "    \n",
    "    print('recommendations')\n",
    "    print(advice_options)\n",
    "\n",
    "    if(len(advice_options) == 0):\n",
    "        mess = 'You have reviewed all information'\n",
    "        mess += '\\n'\n",
    "        mess += 'redirect to main page ... '\n",
    "        \n",
    "        bot.send_message(message.chat.id,mess)\n",
    "        time.sleep(3)\n",
    "        restart(message)\n",
    "    elif(len(advice_options) == 1):\n",
    "        questions =  advice_options\n",
    "    else:\n",
    "        questions =  advice_options[:2]\n",
    "    print(questions)\n",
    "\n",
    "    \n",
    "    markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "    \n",
    "    for index in range(len(questions)):            \n",
    "        found = query(questions[index])\n",
    "        \n",
    "        markup.add(f'''{index} {random.choice(found)['patterns'][0]}''')\n",
    "\n",
    "    markup.add('None')\n",
    "    mess = f'Below are options'\n",
    "    mess += '\\n'\n",
    "    msg = bot.send_message(message.chat.id,mess, reply_markup=markup)\n",
    "    \n",
    "    bot.register_next_step_handler(msg, recommendations_decode,advice_options)\n",
    "        \n",
    "\n",
    "def recommendations_decode(message,questions):\n",
    "    if(message.text == 'None'):\n",
    "        mess = 'redirect to main page ... '      \n",
    "        bot.send_message(message.chat.id,mess)\n",
    "        time.sleep(3)\n",
    "        restart(message)\n",
    "    else:\n",
    "        \n",
    "        questions = questions\n",
    "        select_index = int(message.text.split(' ')[0])\n",
    "\n",
    "        # for future RNN recommendation record\n",
    "        \n",
    "        record.predicted = None\n",
    "        record.message = None\n",
    "        record.response = select_index\n",
    "        record_dialogue(record,'new_response')\n",
    "        \n",
    "        print(questions[select_index])\n",
    "        \n",
    "        mess = ''\n",
    "        found = query(questions[select_index])\n",
    "        \n",
    "        mess += random.choice(found)['responses'][0]\n",
    "        bot.send_message(message.chat.id,mess)\n",
    "        questions.remove(questions[select_index])\n",
    "        \n",
    "        time.sleep(2)  \n",
    "        mess = 'More recommendations below'\n",
    "        bot.send_message(message.chat.id,mess)\n",
    "        recommendations(message,questions)\n",
    "\n",
    "def model_decode(model ,tokenizer,sents,max_length,message,advice_options = None):\n",
    "    \n",
    "    if(len(sents) == 0):\n",
    "        if(advice_options == None):\n",
    "            mess = 'redirect to main page'\n",
    "            bot.send_message(message.chat.id,mess)\n",
    "            \n",
    "            time.sleep(5)\n",
    "            restart(message)\n",
    "        else:\n",
    "            mess = f'Here are some related questions that you might be interested'\n",
    "            mess += '\\n'\n",
    "            \n",
    "            bot.send_message(message.chat.id,mess)\n",
    "            recommendations(message,advice_options)\n",
    "    \n",
    "            \n",
    "    else:\n",
    "        sent = sents[0]\n",
    "        sents.remove(sent)\n",
    "        \n",
    "        print(sent)\n",
    "        print()\n",
    "        \n",
    "        mess = 'Processing ... (it may takes 5 - 10 seconds)'\n",
    "        bot.send_message(message.chat.id, mess)\n",
    "        # encoding and decoding \n",
    "        \n",
    "        indexs , probs = model_process(model,tokenizer,sent,max_length)\n",
    "        prob = probs[0]\n",
    "        index = indexs[0]\n",
    "\n",
    "        print(indexs)\n",
    "        print(index)\n",
    "        \n",
    "        sents_indexs = []\n",
    "        sents_indexs.append(sents)\n",
    "        sents_indexs.append(indexs)\n",
    "        print(prob)\n",
    "        print()\n",
    "\n",
    "        time.sleep(2)\n",
    "        mess = ''\n",
    "        if(prob > 0.15):\n",
    "            found = query(index)\n",
    "            record.message = sent\n",
    "            record.predicted = index\n",
    "            \n",
    "            mess = random.choice(found)['responses'][0]\n",
    "            print(mess)\n",
    "            print()\n",
    "            bot.send_message(message.chat.id, mess)\n",
    "        \n",
    "            #feedback\n",
    "            time.sleep(5)\n",
    "            mess = 'is this response answer your questions ?'\n",
    "            markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "            markup.add('Yes') \n",
    "            markup.add('No') \n",
    "            msg = bot.send_message(message.chat.id,mess, reply_markup=markup)\n",
    "    \n",
    "            \n",
    "            \n",
    "            bot.register_next_step_handler(msg, satisfaction,sents_indexs)\n",
    "        \n",
    "        else:\n",
    "            record.message = sent\n",
    "            record.predicted = None\n",
    "            mess = \"Sorry I am unable to Process Your Request\"\n",
    "            bot.send_message(message.chat.id, mess)\n",
    "\n",
    "            markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "\n",
    "            mess = f'belows are possible answers for your questions : {sent}'\n",
    "            mess += '\\n'\n",
    "            mess += '- - - - - - - - - - - - - - - - - - - - '\n",
    "            mess += '\\n'\n",
    "            mess += '\\n'\n",
    "            \n",
    "            for index in range(len(indexs))[:2]:            \n",
    "\n",
    "                markup.add(str(index))\n",
    "                \n",
    "                found = query(indexs[index])\n",
    "\n",
    "                mess += f'NUMBER {index}.'\n",
    "                mess += '\\n'\n",
    "                mess += random.choice(found)['responses'][0]\n",
    "                mess += '\\n'\n",
    "                mess += '\\n'\n",
    "\n",
    "            bot.send_message(message.chat.id,mess)\n",
    "\n",
    "        \n",
    "            mess = 'For better performance of system, please click the most correspondent response to your question, thank you for the feedback'    \n",
    "            markup.add('None') \n",
    "            msg = bot.send_message(message.chat.id,mess, reply_markup=markup)\n",
    "            bot.register_next_step_handler(msg, record_correct_response,sents_indexs)\n",
    "    \n",
    "\n",
    "\n",
    "def more_questions(message):\n",
    "\n",
    "    sent = message.text\n",
    "    \n",
    "    sent = multiple_question_detect(sent)\n",
    "\n",
    "    model.eval()\n",
    "    max_length = 64\n",
    "    print('item num :')\n",
    "    print(len(sent))\n",
    "    print()\n",
    "    print(sent)\n",
    "    \n",
    "    model_decode(model,tokenizer,sent,max_length,message)\n",
    "\n",
    "\n",
    "\n",
    "def record_correct_response(message,sents_indexs):\n",
    "    other_answer = sents_indexs[1]\n",
    "    sents = sents_indexs[0]\n",
    "    ans = message.text\n",
    "    if(ans == 'None'):\n",
    "        \n",
    "        record.response = None\n",
    "        record_dialogue(record,'unknown_response')\n",
    "        \n",
    "    else:\n",
    "        record.response = other_answer[int(ans)]\n",
    "        print('record_correct_response')\n",
    "        print(record.response)        \n",
    "        print(other_answer[int(ans)])\n",
    "        \n",
    "        #write into database\n",
    "        \n",
    "        record_dialogue(record,'new_response')\n",
    "        \n",
    "        other_answer.remove(other_answer[int(ans)])\n",
    "         \n",
    "    print(record.response)\n",
    "    print('sents')\n",
    "    print(sents)\n",
    "\n",
    "    # redirect to recommeded\n",
    "    \n",
    "    redirect_to_model(message,sents,other_answer)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def satisfaction(message,sents_indexs):\n",
    "    \n",
    "    other_answer = sents_indexs[1]\n",
    "    print(f'other anwer {other_answer}')\n",
    "    print(len(other_answer))\n",
    "    sents = sents_indexs[0]\n",
    " \n",
    "    if(message.text == 'Yes'):\n",
    "        record.response = other_answer[0]\n",
    "        other_answer = other_answer[1:]\n",
    "        print('record.response')        \n",
    "        print(record.response)\n",
    "        \n",
    "        #write into database\n",
    "        now = datetime.now()\n",
    "        now_russia = eastern_tz.localize(now)\n",
    "                \n",
    "        record.time = now_russia\n",
    "        record_dialogue(record,'new_response')\n",
    "        redirect_to_model(message,sents,other_answer)\n",
    "        \n",
    "\n",
    "    elif(message.text == 'No'):\n",
    "        mess = ''\n",
    "        \n",
    "        markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "        \n",
    "        for index in range(len(other_answer))[:2]:            \n",
    "\n",
    "            markup.add(str(index))\n",
    "            \n",
    "            found = query(other_answer[index])\n",
    "            mess += f'<b>NUMBER {index}.</b>'\n",
    "            mess += '\\n'\n",
    "            mess += random.choice(found)['responses'][0]\n",
    "            mess += '\\n'\n",
    "            mess += '\\n'\n",
    "                \n",
    "                #print(random.choice(intent['responses']))\n",
    "        bot.send_message(message.chat.id,mess, parse_mode='html')\n",
    "\n",
    "        \n",
    "        mess += '\\n'\n",
    "        mess = 'For better performance of system, please click the most correspondent response to your question, thank you for the feedback'    \n",
    "        markup.add('None') \n",
    "        msg = bot.send_message(message.chat.id,mess, reply_markup=markup)\n",
    "        bot.register_next_step_handler(msg, record_correct_response,sents_indexs)\n",
    "        \n",
    "    else:\n",
    "        mess = ''\n",
    "        mess = 'I can not understand you, Please follow the instructions'\n",
    "        mess = '\\n'\n",
    "        mess = 'redirect to main page ...'\n",
    "        \n",
    "        msg = bot.send_message(message.chat.id,mess)\n",
    "        time.sleep(3)\n",
    "        restart(message)\n",
    "\n",
    "def redirect_to_model(message,sents,advice_option):\n",
    "    sents = sents\n",
    "\n",
    "    time.sleep(5)\n",
    "    mess = ''\n",
    "    mess += 'if it is still does not answer your question , please follow instruction below'\n",
    "    mess += '\\n'\n",
    "    mess += '- - - - - - - - - - - - - - - - - - - - '\n",
    "    mess += '\\n'\n",
    "    mess += \"You may find the way forward in https://en.itmo.ru/en/viewjep/2/5/Big_Data_and_Machine_Learning.htm\"\n",
    "    mess += '\\n'\n",
    "    mess += \"Or you may write email to coordinator with aakarabintseva@itmo.ru\"\n",
    "    \n",
    "    bot.send_message(message.chat.id,mess)\n",
    "\n",
    "    max_length = 64\n",
    "    model_decode(model,tokenizer,sents,max_length,message,advice_option)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "        main()\n",
    "        bot.polling(none_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35749b42-1b85-4f8a-b96d-617d664ed462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7c0b5-5cdd-451f-af55-8e2691102e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
