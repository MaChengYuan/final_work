{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3187cfdd-0ef5-4088-82d8-81313c258ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirement\n",
      "\n",
      "scholarships\n",
      "\n",
      "batchmates\n",
      "\n",
      "language\n",
      "\n",
      "research topics\n",
      "\n",
      "internship\n",
      "\n",
      "item num :\n",
      "1\n",
      "\n",
      "['when will be exam']\n",
      "when will be exam\n",
      "\n",
      "[0, 4, 18, 6, 3, 15, 7, 10, 22, 23, 12, 9, 2, 11, 1, 17, 20, 5, 16, 19, 14, 13, 21, 8]\n",
      "0\n",
      "0.071591005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from transformers import RobertaModel,RobertaTokenizer\n",
    "class Model_Classifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_labels, dropout):\n",
    "        super(Model_Classifier, self).__init__()\n",
    "        # Instantiate BERT model\n",
    "        self.bert = RobertaModel.from_pretrained('roberta-large')\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout = dropout\n",
    "        self.linear = nn.Linear(self.embedding_dim, self.hidden_dim)\n",
    "        self.Drop = nn.Dropout(self.dropout)\n",
    "        self.linear2 = nn.Linear(self.hidden_dim, self.num_labels)\n",
    "        \n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.hidden_dim),\n",
    "            # nn.Dropout(self.dropout),\n",
    "            #nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.hidden_dim, self.num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "\n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0]\n",
    "\n",
    "        last_hidden_state_cls = self.linear(last_hidden_state_cls)\n",
    "\n",
    "        last_hidden_state_cls = self.Drop(last_hidden_state_cls)\n",
    "        \n",
    "\n",
    "        logits = self.linear2(last_hidden_state_cls)[:, 0, :]\n",
    "\n",
    "        #logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits, last_hidden_state_cls,outputs[0]\n",
    "class QModel_Classifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_labels, dropout,feature_remove_max= True):\n",
    "        super(QModel_Classifier, self).__init__()\n",
    "        # Instantiate BERT model\n",
    "        self.bert = RobertaModel.from_pretrained('roberta-large')\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout = dropout\n",
    "\n",
    "        \n",
    "        divisors = sorted(self.cf(embedding_dim,hidden_dim))\n",
    "        divisors1 = sorted(self.cf(hidden_dim,num_labels))\n",
    "        common_divisors = sorted(set(divisors1) & set(divisors))\n",
    "        if(feature_remove_max == True):\n",
    "            self.n = common_divisors[-1]\n",
    "        else :\n",
    "            self.n = common_divisors[0]\n",
    "        \n",
    "        self.linear = PHMLayer(self.embedding_dim, self.hidden_dim,self.n)\n",
    "        self.Drop = nn.Dropout(self.dropout)\n",
    "        self.linear2 = PHMLayer(self.hidden_dim, self.num_labels,self.n)\n",
    "        \n",
    "\n",
    "    def cf(self,num1,num2):\n",
    "            n=[]\n",
    "            g=gcd(num1, num2)\n",
    "            for i in range(1, int(sqrt(g))+1):\n",
    "                if g%i==0:\n",
    "                    n.append(i)\n",
    "                    if g!=i*i:\n",
    "                        n.append(int(g/i))\n",
    "            return n\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "\n",
    "        last_hidden_state_cls = outputs[0]\n",
    "        #print(last_hidden_state_cls.shape)\n",
    "        last_hidden_state_cls = self.linear(last_hidden_state_cls)\n",
    "        #print(last_hidden_state_cls.shape)\n",
    "        last_hidden_state_cls = self.Drop(last_hidden_state_cls)\n",
    "        #print(last_hidden_state_cls.shape)\n",
    "\n",
    "        logits = self.linear2(last_hidden_state_cls)[:, 0, :]\n",
    "        #print(logits.shape)\n",
    "        # Feed input to classifier to compute logits\n",
    "        #logits = self.classifier(last_hidden_state_cls)\n",
    "        \n",
    "        return logits, last_hidden_state_cls,outputs[0]\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import telebot\n",
    "import time\n",
    "from telebot import types\n",
    "import json\n",
    "import torch\n",
    "import argparse, os\n",
    "\n",
    "import datetime \n",
    "import pymongo\n",
    "\n",
    "class Record():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        \"\"\"\n",
    "        super(Record, self).__init__()\n",
    "        self.name = None\n",
    "        self.id = None\n",
    "        self.message = None\n",
    "        self.predicted = None\n",
    "        self.response = None\n",
    "        self.time = None\n",
    "\n",
    "def dir_path(string):\n",
    "    if os.path.isdir(string):\n",
    "        return string\n",
    "    else:\n",
    "        raise NotADirectoryError(string)\n",
    "        \n",
    "parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('-mp','--main_path', help= 'paste path to main QA.json file')\n",
    "#parser.add_argument('-p','--path', help= 'paste path to test.json file')\n",
    "#parser.add_argument('-m','--model', help= 'paste path to model file', type=dir_path)\n",
    "\n",
    "#args = vars(parser.parse_args())\n",
    "#path_to_main = args[\"path\"]\n",
    "#path_to_test = args[\"path\"]\n",
    "#path_to_data = args[\"model\"]\n",
    "\n",
    "\n",
    "## ----- import pre-trained model\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "import torch\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "eastern_tz = pytz.timezone('Europe/Moscow')\n",
    "\n",
    "\n",
    "class Args():\n",
    "    embedding_dim = 1024\n",
    "    hidden=512 \n",
    "    num_labels = 24\n",
    "    dropout=0.1\n",
    "    \n",
    "args = Args()\n",
    "PATH = r\"itmo_model.pt\"\n",
    "model = Model_Classifier(args.embedding_dim,args.hidden,args.num_labels,args.dropout)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', do_lower_case=True)\n",
    "\n",
    "record = Record()\n",
    "\n",
    "token = '6705181314:AAH1F4h1C_rpM5pkcu3tXdeHkznDxIESz3o'\n",
    "bot = telebot.TeleBot(token, parse_mode='None')\n",
    "bot_name = 'ITMO BOT'\n",
    "\n",
    "#model= torch.load('/Users/mac/Desktop/test/model.pth')\n",
    "\n",
    "\n",
    "def menu():\n",
    "        markup = types.InlineKeyboardMarkup()\n",
    "        markup.add(types.InlineKeyboardButton('help', callback_data='help'))   \n",
    "        markup.add(types.InlineKeyboardButton('contact', callback_data='contact'))   \n",
    "        markup.add(types.InlineKeyboardButton('main questions', callback_data='main questions'))  \n",
    "        markup.add(types.InlineKeyboardButton('more questions', callback_data='more questions')) \n",
    "        markup.add(types.InlineKeyboardButton('application', callback_data='application'))    \n",
    "        return markup\n",
    "def main():       \n",
    "    @bot.message_handler(commands=['start'])  # Ответ на команду /start\n",
    "    def start(message):\n",
    "        mess = f'hi, <b>{message.from_user.first_name}</b>!\\nI am - <b>{bot_name}</b>'\n",
    "\n",
    "        #record name and id \n",
    "        record.id = message.chat.id\n",
    "        record.name = message.from_user.first_name\n",
    "\n",
    "        \n",
    "        markup = menu()\n",
    "        bot.send_message(message.chat.id, mess, reply_markup=markup, parse_mode='html')\n",
    "\n",
    "def restart(message):\n",
    "    mess = f'hi, <b>{message.from_user.first_name}</b>!\\nI am - <b>{bot_name}</b>'\n",
    "    markup = menu()\n",
    "    bot.send_message(message.chat.id, mess, reply_markup=markup, parse_mode='html')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "with open('/Users/mac/Desktop/SCIENTIFIC_RESEARCH/main_QA.json', 'r') as json_data:\n",
    "    main_intents = json.load(json_data)\n",
    "corpse = []\n",
    "responses = []\n",
    "for intent in main_intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    response = intent['responses']\n",
    "    print(tag+\"\\n\")\n",
    "    corpse.append(tag)# here we are appending the word with its tag\n",
    "    responses.append(response)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "@bot.callback_query_handler(func=lambda call: True)\n",
    "def message_reply(call):\n",
    "    if call.data == 'contact':\n",
    "        mess = 'click on mail to get contact with staff'\n",
    "        bot.send_message(call.message.chat.id,mess)\n",
    "        mess = \"\"\"\n",
    "Program coordinator --  aakarabintseva@itmo.ru\n",
    "International office -- international@itmo.ru\n",
    "Student office -- aakiseleva@itmo.ru\n",
    "Migration office -- aakhalilova@itmo.ru \n",
    "\"\"\"\n",
    "        bot.send_message(call.message.chat.id,mess)\n",
    "        time.sleep(5)\n",
    "        restart(call.message)\n",
    "    elif call.data == 'help': \n",
    "        mess = \"\"\"\n",
    "contact --  to find Email address of specific staff in ITMO\n",
    "main questions -- to answer most frequent questions from candidates\n",
    "more questions -- to answer other questions\n",
    "application -- to redirect to page to fill application\n",
    "\"\"\"\n",
    "        bot.send_message(call.message.chat.id,mess)\n",
    "        time.sleep(5)\n",
    "        restart(call.message)\n",
    "    elif call.data == 'main questions':\n",
    "        mess = 'please choose interested item'\n",
    "        markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "        for i in range(len(corpse)):            \n",
    "            markup.add(corpse[i])  \n",
    "        msg = bot.send_message(call.message.chat.id,mess, reply_markup=markup)\n",
    "        bot.register_next_step_handler(msg, main_questions)\n",
    "    elif call.data == 'more questions':\n",
    "        msg = bot.send_message(call.message.chat.id, 'please write to questions')\n",
    "        bot.register_next_step_handler(msg, more_questions)\n",
    "    elif call.data == 'application':\n",
    "        linked_user = 'https://signup.itmo.ru/master'\n",
    "        markup = types.InlineKeyboardMarkup()\n",
    "        markup.add(types.InlineKeyboardButton(text='redirect to ITMO',\n",
    "                            url=linked_user))\n",
    "        mess = 'click to redirect to application form'\n",
    "        bot.send_message(call.message.chat.id,mess, reply_markup=markup)\n",
    "        time.sleep(5)\n",
    "        restart(call.message)\n",
    "    \n",
    "\n",
    "\n",
    "def main_questions(message):\n",
    "    mess = None\n",
    "    if(message.text == 'None'):\n",
    "        mess = 'redirecting to menu ...'\n",
    "        bot.send_message(message.chat.id, mess,reply_markup=types.ReplyKeyboardRemove())\n",
    "\n",
    "        time.sleep(5)\n",
    "        restart(message)\n",
    "        \n",
    "    elif(message.text in corpse):\n",
    "        msg = responses[corpse.index(message.text)][0]\n",
    "        print(f\"{bot_name}: \"+msg)\n",
    "        mess = msg\n",
    "    else:\n",
    "        msg = 'You must click one of the options!'\n",
    "        print(f\"{bot_name}: \"+msg)\n",
    "        mess = msg\n",
    "\n",
    "    \n",
    "    bot.send_message(message.chat.id, mess,reply_markup=types.ReplyKeyboardRemove())\n",
    "\n",
    "    time.sleep(5)\n",
    "    main_questions_function(message)\n",
    "    \n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def record_dialogue(record,name):\n",
    "    token = 'mongodb+srv://mongo:mongo@cluster0.gcj8po2.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0'\n",
    "    myclient = pymongo.MongoClient(token)\n",
    "    mydb = myclient[\"itmo_data\"]\n",
    "    mycol = mydb[name]\n",
    "    #mycol = mydb[\"customers\"]\n",
    "    now = datetime.now()\n",
    "    now_russia = eastern_tz.localize(now)            \n",
    "\n",
    "    mydict = { \"name\": record.name , \"id\": record.id, \"message\": record.message, \"predicted\":record.predicted, \"response\":record.response ,\"time\": now_russia }   \n",
    "    \n",
    "    x = mycol.insert_one(mydict)\n",
    "\n",
    "def query(keylabel):\n",
    "    token = 'mongodb+srv://mongo:mongo@cluster0.gcj8po2.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0'\n",
    "    \n",
    "    myclient = pymongo.MongoClient(token)\n",
    "    \n",
    "    mydb = myclient[\"itmo_data\"]\n",
    "    \n",
    "    mycol = mydb[\"original\"]\n",
    "    \n",
    "    myquery = { \"tag\": keylabel }\n",
    "    \n",
    "    mydoc = mycol.find(myquery)\n",
    "    found = []\n",
    "    \n",
    "    for x in mydoc:\n",
    "      found.append(x)\n",
    "        \n",
    "    return found\n",
    "    \n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "import spacy\n",
    "import random\n",
    "import re\n",
    "from torch import nn\n",
    "\n",
    "max_length = 64     \n",
    "\n",
    "\n",
    "def maximum(list):\n",
    "    output = list.sort()\n",
    "    return output[0][-3:] , output[1][-3:]\n",
    "    #return [output[1][-1],output[1][-2],output[1][-3]]\n",
    "def multiple_question_detect(sent):\n",
    "    if(type(sent) == list):\n",
    "        return sent\n",
    "    sent = sent.replace('?',' ?')\n",
    "    sent = re.sub(r'\\s\\s+',' ',sent)\n",
    "    sent = re.sub(r\"^\\s+|\\s+$\", \"\", sent)\n",
    "    sent = re.split('(?<=[.!?,]) +',sent)\n",
    "    texts = []\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = re.sub('[^a-zA-Z0-9 ]', '', sent[i])\n",
    "        sent[i] = re.sub(r\"^\\s+|\\s+$\", \"\", sent[i])\n",
    "        if(len(sent[i])==0):\n",
    "            texts.append(sent[i])\n",
    "    \n",
    "    for i in texts :\n",
    "        sent.remove(i)\n",
    "    return sent\n",
    "\n",
    "def recommendations(message,advice_options):\n",
    "    \n",
    "    print('recommendations')\n",
    "    print(advice_options)\n",
    "\n",
    "    if(len(advice_options) == 0):\n",
    "        mess = 'You have reviewed all information'\n",
    "        mess += '\\n'\n",
    "        mess += 'redirect to main page ... '\n",
    "        \n",
    "        bot.send_message(message.chat.id,mess)\n",
    "        time.sleep(3)\n",
    "        restart(message)\n",
    "    elif(len(advice_options) == 1):\n",
    "        questions =  advice_options\n",
    "    else:\n",
    "        questions =  advice_options[:2]\n",
    "    print(questions)\n",
    "\n",
    "    \n",
    "    markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "    \n",
    "    for index in range(len(questions)):            \n",
    "        found = query(questions[index])\n",
    "        \n",
    "        markup.add(f'''{index} {random.choice(found)['patterns'][0]}''')\n",
    "\n",
    "    markup.add('None')\n",
    "    mess = f'Below are options'\n",
    "    mess += '\\n'\n",
    "    msg = bot.send_message(message.chat.id,mess, reply_markup=markup)\n",
    "    \n",
    "    bot.register_next_step_handler(msg, recommendations_decode,advice_options)\n",
    "        \n",
    "\n",
    "def recommendations_decode(message,questions):\n",
    "    if(message.text == 'None'):\n",
    "        time.sleep(3)\n",
    "        restart(message)\n",
    "    else:\n",
    "        \n",
    "        questions = questions\n",
    "        select_index = int(message.text.split(' ')[0])\n",
    "\n",
    "        # for future RNN recommendation record\n",
    "        \n",
    "        record.predicted = None\n",
    "        record.message = None\n",
    "        record.response = select_index\n",
    "        record_dialogue(record,'new_response')\n",
    "        \n",
    "        print(questions[select_index])\n",
    "        \n",
    "        mess = ''\n",
    "        found = query(questions[select_index])\n",
    "        \n",
    "        mess += random.choice(found)['responses'][0]\n",
    "        bot.send_message(message.chat.id,mess)\n",
    "        questions.remove(questions[select_index])\n",
    "        \n",
    "        time.sleep(2)  \n",
    "        mess = 'More recommendations below'\n",
    "        bot.send_message(message.chat.id,mess)\n",
    "        recommendations(message,questions)\n",
    "\n",
    "def model_decode(model ,tokenizer,sents,max_length,message,advice_options = None):\n",
    "    \n",
    "    if(len(sents) == 0):\n",
    "        if(advice_options == None):\n",
    "            mess = 'redirect to main page'\n",
    "            bot.send_message(message.chat.id,mess)\n",
    "            \n",
    "            time.sleep(5)\n",
    "            restart(message)\n",
    "        else:\n",
    "            mess = f'Here are some related questions that you might be interested'\n",
    "            mess += '\\n'\n",
    "            \n",
    "            bot.send_message(message.chat.id,mess)\n",
    "            recommendations(message,advice_options)\n",
    "    \n",
    "            \n",
    "    else:\n",
    "        sent = sents[0]\n",
    "        sents.remove(sent)\n",
    "        \n",
    "        print(sent)\n",
    "        print()\n",
    "\n",
    "\n",
    "        mess = 'Processing ... (it may takes 5 - 10 seconds)'\n",
    "        bot.send_message(message.chat.id, mess)\n",
    "        # encoding and decoding \n",
    "        encoding = tokenizer(sent, return_tensors='pt', max_length=max_length, truncation=True)\n",
    "        b_input_ids = encoding['input_ids']\n",
    "        #token_type_ids = encoding['token_type_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        outputs = model(b_input_ids, \n",
    "                        attention_mask=attention_mask)\n",
    "        m = nn.Softmax(dim=1)\n",
    "        outputs= m(outputs[0])\n",
    "        output_list = outputs[0].detach().numpy()\n",
    "    \n",
    "        # first 3 tags\n",
    "        \n",
    "        indexs = sorted(range(len(output_list)), key=lambda k: output_list[k], reverse=True)     \n",
    "        probs = output_list[indexs]\n",
    "        prob = probs[0]\n",
    "        index = indexs[0]\n",
    "\n",
    "        print(indexs)\n",
    "        print(index)\n",
    "        \n",
    "        sents_indexs = []\n",
    "        sents_indexs.append(sents)\n",
    "        sents_indexs.append(indexs)\n",
    "        print(prob)\n",
    "        print()\n",
    "\n",
    "        time.sleep(2)\n",
    "        mess = ''\n",
    "        if(prob > 0.15):\n",
    "            found = query(index)\n",
    "\n",
    "            record.message = sent\n",
    "            record.predicted = index\n",
    "            \n",
    "            mess = random.choice(found)['responses'][0]\n",
    "            print(mess)\n",
    "            print()\n",
    "            bot.send_message(message.chat.id, mess)\n",
    "        \n",
    "            #feedback\n",
    "            time.sleep(5)\n",
    "            mess = 'is this response answer your questions ?'\n",
    "            markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "            markup.add('Yes') \n",
    "            markup.add('No') \n",
    "            msg = bot.send_message(message.chat.id,mess, reply_markup=markup)\n",
    "    \n",
    "            \n",
    "            \n",
    "            bot.register_next_step_handler(msg, satisfaction,sents_indexs)\n",
    "        \n",
    "        else:\n",
    "            record.message = sent\n",
    "            record.predicted = None\n",
    "            mess = \"Sorry I am unable to Process Your Request\"\n",
    "            bot.send_message(message.chat.id, mess)\n",
    "\n",
    "            markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "\n",
    "            mess = f'belows are possible answers for your questions : {sent}'\n",
    "            mess += '\\n'\n",
    "            mess += '- - - - - - - - - - - - - - - - - - - - '\n",
    "            mess += '\\n'\n",
    "            mess += '\\n'\n",
    "            \n",
    "            for index in range(len(indexs))[:2]:            \n",
    "\n",
    "                markup.add(str(index))\n",
    "                \n",
    "                found = query(indexs[index])\n",
    "\n",
    "                mess += f'NUMBER {index}.'\n",
    "                mess += '\\n'\n",
    "                mess += random.choice(found)['responses'][0]\n",
    "                mess += '\\n'\n",
    "                mess += '\\n'\n",
    "\n",
    "            bot.send_message(message.chat.id,mess)\n",
    "\n",
    "        \n",
    "            mess = 'For better performance of system, please click the most correspondent response to your question, thank you for the feedback'    \n",
    "            markup.add('None') \n",
    "            msg = bot.send_message(message.chat.id,mess, reply_markup=markup)\n",
    "            bot.register_next_step_handler(msg, record_correct_response,sents_indexs)\n",
    "    \n",
    "\n",
    "\n",
    "def more_questions(message):\n",
    "\n",
    "    sent = message.text\n",
    "    \n",
    "    sent = multiple_question_detect(sent)\n",
    "\n",
    "    model.eval()\n",
    "    max_length = 64\n",
    "    print('item num :')\n",
    "    print(len(sent))\n",
    "    print()\n",
    "    print(sent)\n",
    "    \n",
    "    model_decode(model,tokenizer,sent,max_length,message)\n",
    "\n",
    "\n",
    "\n",
    "def record_correct_response(message,sents_indexs):\n",
    "    other_answer = sents_indexs[1]\n",
    "    sents = sents_indexs[0]\n",
    "    ans = message.text\n",
    "    if(ans == 'None'):\n",
    "        \n",
    "        record.response = None\n",
    "        record_dialogue(record,'unknown_response')\n",
    "        \n",
    "    else:\n",
    "        record.response = other_answer[int(ans)]\n",
    "        print('record_correct_response')\n",
    "        print(record.response)        \n",
    "        print(other_answer[int(ans)])\n",
    "        \n",
    "        #write into database\n",
    "        \n",
    "        record_dialogue(record,'new_response')\n",
    "        \n",
    "        other_answer.remove(other_answer[int(ans)])\n",
    "         \n",
    "    print(record.response)\n",
    "    print('sents')\n",
    "    print(sents)\n",
    "\n",
    "    # redirect to recommeded\n",
    "    \n",
    "    redirect_to_model(message,sents,other_answer)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def satisfaction(message,sents_indexs):\n",
    "    \n",
    "    other_answer = sents_indexs[1]\n",
    "    print(f'other anwer {other_answer}')\n",
    "    print(len(other_answer))\n",
    "    sents = sents_indexs[0]\n",
    " \n",
    "    if(message.text == 'Yes'):\n",
    "        record.response = other_answer[0]\n",
    "        other_answer = other_answer[1:]\n",
    "        print('record.response')        \n",
    "        print(record.response)\n",
    "        \n",
    "        #write into database\n",
    "        now = datetime.now()\n",
    "        now_russia = eastern_tz.localize(now)\n",
    "                \n",
    "        record.time = now_russia\n",
    "        record_dialogue(record,'new_response')\n",
    "        redirect_to_model(message,sents,other_answer)\n",
    "        \n",
    "\n",
    "    elif(message.text == 'No'):\n",
    "        mess = ''\n",
    "        \n",
    "        markup = types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "        \n",
    "        for index in range(len(other_answer))[:2]:            \n",
    "\n",
    "            markup.add(str(index))\n",
    "            \n",
    "            found = query(other_answer[index])\n",
    "            mess += f'<b>NUMBER {index}.</b>'\n",
    "            mess += '\\n'\n",
    "            mess += random.choice(found)['responses'][0]\n",
    "            mess += '\\n'\n",
    "            mess += '\\n'\n",
    "                \n",
    "                #print(random.choice(intent['responses']))\n",
    "        bot.send_message(message.chat.id,mess, parse_mode='html')\n",
    "\n",
    "        \n",
    "        mess += '\\n'\n",
    "        mess = 'For better performance of system, please click the most correspondent response to your question, thank you for the feedback'    \n",
    "        markup.add('None') \n",
    "        msg = bot.send_message(message.chat.id,mess, reply_markup=markup)\n",
    "        bot.register_next_step_handler(msg, record_correct_response,sents_indexs)\n",
    "        \n",
    "    else:\n",
    "        mess = ''\n",
    "        mess = 'I can not understand you, Please follow the instructions'\n",
    "        mess = '\\n'\n",
    "        mess = 'redirect to main page ...'\n",
    "        \n",
    "        msg = bot.send_message(message.chat.id,mess)\n",
    "        time.sleep(3)\n",
    "        restart(message)\n",
    "\n",
    "def redirect_to_model(message,sents,advice_option):\n",
    "    sents = sents\n",
    "\n",
    "    time.sleep(5)\n",
    "    mess = ''\n",
    "    mess += 'if it is still does not answer your question , please follow instruction below'\n",
    "    mess += '\\n'\n",
    "    mess += '- - - - - - - - - - - - - - - - - - - - '\n",
    "    mess += '\\n'\n",
    "    mess += \"You may find the way forward in https://en.itmo.ru/en/viewjep/2/5/Big_Data_and_Machine_Learning.htm\"\n",
    "    mess += '\\n'\n",
    "    mess += \"Or you may write email to coordinator with aakarabintseva@itmo.ru\"\n",
    "    \n",
    "    bot.send_message(message.chat.id,mess)\n",
    "\n",
    "    max_length = 64\n",
    "    model_decode(model,tokenizer,sents,max_length,message,advice_option)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "        main()\n",
    "        bot.polling(none_stop=True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
